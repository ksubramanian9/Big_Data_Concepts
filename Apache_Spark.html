<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Unified Analytics Engine: An Interactive Guide to Apache Spark</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- Chosen Palette: Slate & Sky Blue -->
    <!-- Application Structure Plan: The application is designed as a single-page, scrollable journey through the world of Apache Spark. The structure is thematic rather than linear, starting with a high-level overview and then allowing users to dive into specific areas of interest (History, Architecture, APIs, Ecosystem, Deployment, Use Cases). This non-linear, exploratory approach is more engaging for a technical audience who may want to jump to specific topics. Key interactions include hover effects for quick info, clickable cards to reveal detailed explanations, and dynamic charts for comparisons. This structure was chosen to make a dense technical report digestible and engaging, encouraging exploration over passive reading. -->
    <!-- Visualization & Content Choices: 
        - History -> Goal: Show evolution -> Viz: Interactive vertical timeline -> Interaction: Scroll-based highlighting -> Justification: More engaging than a list of dates.
        - Architecture -> Goal: Explain core components -> Viz: Clickable diagram -> Interaction: Click to reveal component descriptions -> Justification: Visualizes relationships better than text.
        - API Comparison -> Goal: Compare RDDs, DataFrames, Datasets -> Viz: Dynamic Radar Chart (Chart.js) -> Interaction: Buttons to switch data views -> Justification: Provides a multi-dimensional, at-a-glance comparison.
        - Cluster Managers -> Goal: Compare deployment options -> Viz: Dynamic Bar Chart (Chart.js) -> Interaction: Buttons to update chart data -> Justification: Makes quantitative and qualitative differences easy to see.
        - Use Cases -> Goal: Showcase real-world applications -> Viz: Grid of interactive cards -> Interaction: Hover/click to see details -> Justification: Clean, organized way to present diverse examples.
        - All text content is presented in expandable sections or cards to avoid overwhelming the user with information upfront.
    -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #add8e6;
            color: #1e293b;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 700px;
            margin-left: auto;
            margin-right: auto;
            height: 350px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 400px;
            }
        }
        .nav-link {
            transition: color 0.3s ease, border-bottom-color 0.3s ease;
        }
        .nav-link:hover {
            color: #0284c7;
        }
        .active-link {
            color: #0284c7;
            border-bottom: 2px solid #0284c7;
        }
        .timeline-item::before {
            content: '';
            position: absolute;
            width: 1.25rem;
            height: 1.25rem;
            border-radius: 50%;
            left: -0.625rem;
            top: 0;
            background-color: #f1f5f9;
            border: 4px solid #0ea5e9;
        }
        .card-hover {
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        .card-hover:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }
        .timeline-diagram {
            position: relative;
            padding-left: 2.5rem;
        }
        .timeline-diagram::before {
            content: '';
            position: absolute;
            left: 1rem;
            top: 0;
            bottom: 0;
            width: 2px;
            background: linear-gradient(180deg, rgba(14, 165, 233, 0.15), rgba(14, 165, 233, 0.7));
        }
        .timeline-year {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            background-color: #0ea5e9;
            color: white;
            border-radius: 9999px;
            font-weight: 600;
            font-size: 0.875rem;
        }
        .spark-ecosystem-diagram {
            position: relative;
            max-width: 640px;
            margin: 0 auto;
            min-height: 320px;
        }
        .spark-ecosystem-center {
            position: relative;
            z-index: 10;
        }
        .spark-ecosystem-node {
            position: absolute;
            background-color: white;
            border-radius: 9999px;
            box-shadow: 0 10px 25px -15px rgba(15, 23, 42, 0.5);
            padding: 0.75rem 1rem;
            font-weight: 600;
            color: #0f172a;
            min-width: 130px;
            text-align: center;
        }
        .architecture-blocks {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1.5rem;
            align-items: stretch;
        }
        .architecture-block {
            background: white;
            border-radius: 1rem;
            border: 1px solid #e2e8f0;
            padding: 1.5rem;
            box-shadow: 0 15px 35px -25px rgba(15, 23, 42, 0.5);
        }
        .workflow-diagram {
            display: grid;
            gap: 1.5rem;
        }
        @media (min-width: 768px) {
            .workflow-diagram {
                grid-template-columns: repeat(3, minmax(0, 1fr));
                align-items: center;
            }
        }
        .workflow-node {
            background: white;
            border-radius: 1rem;
            border: 1px solid #e2e8f0;
            padding: 1.5rem;
            text-align: center;
            box-shadow: 0 15px 35px -25px rgba(15, 23, 42, 0.5);
        }
        .workflow-arrow {
            text-align: center;
            font-size: 2.5rem;
            color: #0ea5e9;
        }
        @media (max-width: 640px) {
            .spark-ecosystem-diagram {
                min-height: 420px;
            }
            .spark-ecosystem-node {
                position: static;
                transform: none !important;
                margin: 0.5rem auto;
                display: block;
            }
            .spark-ecosystem-center {
                margin-bottom: 1rem;
            }
        }
    </style>
</head>
<body class="bg-slate-50">

    <header class="bg-white/80 backdrop-blur-lg sticky top-0 z-50 shadow-sm">
        <nav class="container mx-auto px-6 py-4 flex justify-between items-center">
            <h1 class="text-2xl font-bold text-slate-800">
                <span class="text-sky-600">Apache</span> Spark
            </h1>
            <div class="hidden md:flex space-x-8">
                <a href="index.html" class="nav-link text-slate-600 font-medium pb-1">Home</a>
                <a href="#genesis" class="nav-link text-slate-600 font-medium pb-1">Genesis</a>
                <a href="#architecture" class="nav-link text-slate-600 font-medium pb-1">Architecture</a>
                <a href="#ecosystem" class="nav-link text-slate-600 font-medium pb-1">Ecosystem</a>
                <a href="#deployment" class="nav-link text-slate-600 font-medium pb-1">Deployment</a>
                <a href="#use-cases" class="nav-link text-slate-600 font-medium pb-1">Use Cases</a>
            </div>
        </nav>
    </header>

    <main class="container mx-auto px-6 py-12">
        <section id="hero" class="text-center mb-24">
            <h2 class="text-4xl md:text-6xl font-extrabold text-slate-900 mb-4">The Unified Analytics Engine</h2>
            <p class="max-w-3xl mx-auto text-lg text-slate-600 mb-8">
                An interactive exploration of Apache Spark, the open-source engine that revolutionized large-scale data processing with its speed, versatility, and powerful architecture.
            </p>
            <div class="grid grid-cols-1 md:grid-cols-3 gap-8 max-w-4xl mx-auto">
                <div class="bg-white p-6 rounded-xl shadow-md card-hover">
                    <div class="text-3xl mb-2">‚ö°Ô∏è</div>
                    <h3 class="text-xl font-bold text-slate-800 mb-2">Unmatched Speed</h3>
                    <p class="text-slate-500">Up to 100x faster than Hadoop MapReduce through in-memory processing and optimized execution.</p>
                </div>
                <div class="bg-white p-6 rounded-xl shadow-md card-hover">
                    <div class="text-3xl mb-2">üß©</div>
                    <h3 class="text-xl font-bold text-slate-800 mb-2">Unified Platform</h3>
                    <p class="text-slate-500">A single engine for batch, streaming, SQL, machine learning, and graph processing.</p>
                </div>
                <div class="bg-white p-6 rounded-xl shadow-md card-hover">
                    <div class="text-3xl mb-2">üíª</div>
                    <h3 class="text-xl font-bold text-slate-800 mb-2">Developer Friendly</h3>
                    <p class="text-slate-500">High-level APIs in Python, Scala, Java, and R simplify complex data manipulation.</p>
                </div>
            </div>
            <p class="max-w-3xl mx-auto mt-8 text-base text-slate-600">Because Spark keeps intermediate datasets in memory and aggressively pipelines operations, iterative analytics and streaming workloads complete dramatically faster than Hadoop MapReduce, which repeatedly writes every stage to disk. The practical result is that jobs that might take hours under MapReduce can often finish in minutes with Spark.</p>
        </section>

        <section id="genesis" class="mb-24 scroll-mt-20">
            <h2 class="text-3xl font-bold text-center text-slate-900 mb-4">The Genesis of Spark</h2>
            <p class="text-lg text-slate-600 text-center max-w-3xl mx-auto mb-12">This section traces Spark's journey from a university research project to a global standard in big data. The timeline below highlights the key milestones that marked its evolution, showcasing how a paradigm shift from disk-based to in-memory processing addressed the critical limitations of its predecessors.</p>
            <div class="timeline-diagram">
                <div class="space-y-12">
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2009</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Research Origins</h4>
                        <p class="text-slate-600">Spark begins at UC Berkeley's AMPLab to deliver a unified engine that keeps intermediate data in memory, eliminating MapReduce's disk bottlenecks for iterative workloads.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2010</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Open-Source Debut</h4>
                        <p class="text-slate-600">The code is released under a BSD license. Contributions from outside academia accelerate feature development and real-world adoption.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2012</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Spark 0.7 &amp; Shark</h4>
                        <p class="text-slate-600">The AMPLab introduces <span class="font-semibold">Shark</span>, a SQL layer on Spark, and releases Spark 0.7 with resilient distributed datasets (RDDs) as a stable abstraction.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2013</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Apache Incubation</h4>
                        <p class="text-slate-600">Spark enters the Apache Software Foundation and quickly becomes one of the fastest-growing open-source communities in big data.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2014</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Spark 1.x Era</h4>
                        <p class="text-slate-600">Spark graduates to a Top-Level Project. Versions 1.0‚Äì1.6 add MLlib, GraphX, and Spark Streaming, establishing the unified analytics vision.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2016</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Spark 2.0 &amp; Structured APIs</h4>
                        <p class="text-slate-600">Catalyst and Tungsten mature, DataFrames become the default abstraction, and Structured Streaming delivers end-to-end exactly-once semantics.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2018</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Delta, Kubernetes, &amp; AI</h4>
                        <p class="text-slate-600">Open-sourced Delta Lake and native Kubernetes scheduler arrive, aligning Spark with cloud-native deployments and machine learning pipelines.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2020</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Spark 3.0 GA</h4>
                        <p class="text-slate-600">Adaptive query execution, dynamic partition pruning, and GPU acceleration land, positioning Spark for modern lakehouse architectures.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2023</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Lakehouse Acceleration</h4>
                        <p class="text-slate-600">Releases 3.4 and 3.5 focus on Python UDF performance, pandas API improvements, and tighter integration with Delta Lake and Iceberg.</p>
                    </div>
                    <div class="relative pl-10 timeline-item">
                        <span class="timeline-year">2024</span>
                        <h4 class="font-bold text-lg text-sky-700 mt-2">Spark 4.0 Preview</h4>
                        <p class="text-slate-600">Preview builds showcase <span class="font-semibold">Project Zen</span> for simplified configuration, native Connect API for remote execution, and continued optimizations for AI/ML workloads.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="architecture" class="mb-24 scroll-mt-20">
            <h2 class="text-3xl font-bold text-center text-slate-900 mb-4">Core Architecture & Principles</h2>
            <p class="text-lg text-slate-600 text-center max-w-3xl mx-auto mb-12">At its core, Spark's performance and resilience are driven by a sophisticated architecture and foundational principles. This section breaks down the key components and concepts. Explore the interactive diagram to understand how the Driver, Executors, and Cluster Manager work together, and learn about the evolution of Spark's data abstractions.</p>
            
            <div class="grid grid-cols-1 lg:grid-cols-2 gap-12 items-center">
                <div>
                    <h3 class="text-2xl font-bold text-slate-800 mb-4">The Spark Runtime</h3>
                    <p class="text-slate-600 mb-6">A Spark application runs as a set of independent processes, orchestrated by the Driver Program. Click on each component below to learn more about its role.</p>
                    <div id="architecture-diagram" class="space-y-4">
                        <div class="bg-white p-4 rounded-lg shadow-sm border border-slate-200 cursor-pointer" onclick="showInfo('driver')">
                            <h5 class="font-bold text-sky-600">Driver Program</h5>
                        </div>
                        <div class="bg-white p-4 rounded-lg shadow-sm border border-slate-200 cursor-pointer" onclick="showInfo('manager')">
                            <h5 class="font-bold text-sky-600">Cluster Manager</h5>
                        </div>
                        <div class="bg-white p-4 rounded-lg shadow-sm border border-slate-200 cursor-pointer" onclick="showInfo('executor')">
                            <h5 class="font-bold text-sky-600">Executors</h5>
                        </div>
                    </div>
                </div>
                <div id="architecture-info" class="bg-white p-8 rounded-xl shadow-lg min-h-[250px] flex flex-col justify-center">
                    <h4 id="info-title" class="text-xl font-bold text-slate-800 mb-2">Click a component</h4>
                    <p id="info-text" class="text-slate-600">Select a component from the diagram to see its description here.</p>
                </div>
            </div>
            <p class="max-w-3xl mx-auto mt-8 text-base text-slate-600 text-center">In every deployment, the cluster manager (Standalone, YARN, Mesos, or Kubernetes) is the resource broker that hands out CPU and memory to executors so the driver can schedule tasks efficiently across the cluster.</p>

            <div class="bg-gradient-to-r from-sky-50 to-white border border-sky-100 rounded-2xl p-8 mt-12">
                <h3 class="text-2xl font-bold text-slate-800 text-center mb-6">Spark Architecture at a Glance</h3>
                <p class="text-slate-600 text-center max-w-3xl mx-auto mb-10">The labeled block diagram below is a quick reference for exam-style answers. It highlights how Spark Core works alongside the catalog, shuffle service, and application components that ride on top of the engine.</p>
                <div class="architecture-blocks">
                    <div class="architecture-block">
                        <h4 class="text-lg font-semibold text-sky-700 mb-2">Driver Layer</h4>
                        <p class="text-slate-600">Hosts the SparkSession and SparkContext, maintains the DAG Scheduler, and coordinates the logical plan that will be translated into stages and tasks.</p>
                    </div>
                    <div class="architecture-block">
                        <h4 class="text-lg font-semibold text-sky-700 mb-2">Cluster Management</h4>
                        <p class="text-slate-600">External services such as YARN, Mesos, or Kubernetes allocate executors, monitor health, and provide the heartbeat signals Spark relies on for resiliency.</p>
                    </div>
                    <div class="architecture-block">
                        <h4 class="text-lg font-semibold text-sky-700 mb-2">Executor Pool</h4>
                        <p class="text-slate-600">Worker JVMs or Python processes that run tasks, cache RDD/DataFrame partitions, and stream shuffle data between stages.</p>
                    </div>
                    <div class="architecture-block">
                        <h4 class="text-lg font-semibold text-sky-700 mb-2">Persistent Storage</h4>
                        <p class="text-slate-600">HDFS, S3, Azure Data Lake, or on-prem object stores that feed input data and capture checkpoints for long-running streaming jobs.</p>
                    </div>
                    <div class="architecture-block">
                        <h4 class="text-lg font-semibold text-sky-700 mb-2">Application Libraries</h4>
                        <p class="text-slate-600">Spark SQL, MLlib, GraphX, and Structured Streaming modules plug into Spark Core APIs to deliver higher-level analytics without rewriting infrastructure.</p>
                    </div>
                    <div class="architecture-block">
                        <h4 class="text-lg font-semibold text-sky-700 mb-2">Shuffle &amp; Catalog Services</h4>
                        <p class="text-slate-600">External shuffle services and the Hive metastore/Glue Data Catalog maintain metadata, optimize joins, and keep data consistent across workloads.</p>
                    </div>
                </div>
            </div>

        </section>

        <section id="execution" class="mb-24 scroll-mt-20">
            <h2 class="text-3xl font-bold text-center text-slate-900 mb-4">From Code to Cluster: Spark Execution Workflow</h2>
            <p class="text-lg text-slate-600 text-center max-w-3xl mx-auto mb-12">Understanding the life cycle of a Spark job is key for tuning performance. The diagram traces how drivers, cluster managers, and executors interact from application submission to task completion.</p>
            <div class="bg-gradient-to-r from-white to-sky-50 border border-sky-100 rounded-2xl p-10">
                <div class="workflow-diagram">
                    <div class="workflow-node">
                        <h3 class="text-xl font-semibold text-sky-700 mb-2">1. Driver Program</h3>
                        <p class="text-slate-600">User code creates a <span class="font-semibold">SparkSession</span>, builds the logical plan (DAG), and requests resources from the cluster manager.</p>
                    </div>
                    <div class="workflow-arrow">
                        <span class="hidden md:inline">‚ü∂</span>
                        <span class="md:hidden block">‚¨áÔ∏è</span>
                    </div>
                    <div class="workflow-node">
                        <h3 class="text-xl font-semibold text-sky-700 mb-2">2. Cluster Manager</h3>
                        <p class="text-slate-600">YARN, Mesos, Kubernetes, or Standalone allocates executors, responds to heartbeats, and reports cluster health.</p>
                    </div>
                    <div class="workflow-arrow md:col-span-3">
                        <span>‚ü∂</span>
                    </div>
                    <div class="workflow-node md:col-span-3">
                        <h3 class="text-xl font-semibold text-sky-700 mb-2">3. Executors Execute Tasks</h3>
                        <p class="text-slate-600">Executors pull tasks from the scheduler, execute transformations, spill or cache partitions, and send shuffle outputs to peer nodes until the action completes.</p>
                    </div>
                </div>
                <div class="grid md:grid-cols-2 gap-6 mt-10">
                    <div class="bg-white rounded-xl border border-slate-200 p-6 shadow-sm">
                        <h4 class="text-lg font-semibold text-slate-800 mb-2">Stage Lifecycle</h4>
                        <p class="text-slate-600">Spark divides the DAG into stages at shuffle boundaries. Tasks within a stage run in parallel across executors, retry on failure, and report metrics back to the driver UI.</p>
                    </div>
                    <div class="bg-white rounded-xl border border-slate-200 p-6 shadow-sm">
                        <h4 class="text-lg font-semibold text-slate-800 mb-2">Streaming &amp; Batch</h4>
                        <p class="text-slate-600">Structured Streaming uses the same engine, but wraps the execution in micro-batches or continuous processing, checkpointing offsets for exactly-once guarantees.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="ecosystem" class="mb-24 scroll-mt-20">
            <h2 class="text-3xl font-bold text-center text-slate-900 mb-4">A Unified Ecosystem</h2>
            <p class="text-lg text-slate-600 text-center max-w-3xl mx-auto mb-12">Spark is more than just a processing engine; it's a comprehensive ecosystem of libraries that work together seamlessly. This design allows you to combine different workloads, like SQL queries and machine learning, within a single application. Explore the core components of this powerful, unified stack.</p>
            <p class="text-base text-slate-600 text-center max-w-3xl mx-auto mb-8">The core modules include <span class="font-semibold">Spark Core</span> for RDD processing, <span class="font-semibold">Spark SQL</span> for structured queries, <span class="font-semibold">Spark Streaming</span> and <span class="font-semibold">Structured Streaming</span> for real-time pipelines, <span class="font-semibold">MLlib</span> for machine learning, and <span class="font-semibold">GraphX</span> for graph analytics.</p>
            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8">
                <div class="bg-white p-6 rounded-xl shadow-md text-center card-hover">
                    <div class="text-4xl mb-3">‚öôÔ∏è</div>
                    <h3 class="text-xl font-bold text-slate-800 mb-2">Spark Core</h3>
                    <p class="text-slate-500">The foundational engine for scheduling, dispatching, and I/O, providing the RDD abstraction.</p>
                </div>
                <div class="bg-white p-6 rounded-xl shadow-md text-center card-hover">
                    <div class="text-4xl mb-3">üìä</div>
                    <h3 class="text-xl font-bold text-slate-800 mb-2">Spark SQL</h3>
                    <p class="text-slate-500">For querying structured data via SQL or the DataFrame API, the standard for ETL.</p>
                </div>
                <div class="bg-white p-6 rounded-xl shadow-md text-center card-hover">
                    <div class="text-4xl mb-3">üåä</div>
                    <h3 class="text-xl font-bold text-slate-800 mb-2">Spark Streaming</h3>
                    <p class="text-slate-500">Enables scalable, high-throughput, fault-tolerant processing of live data streams.</p>
                </div>
                <div class="bg-white p-6 rounded-xl shadow-md text-center card-hover">
                    <div class="text-4xl mb-3">üß†</div>
                    <h3 class="text-xl font-bold text-slate-800 mb-2">MLlib</h3>
                    <p class="text-slate-500">A scalable Machine Learning library with common algorithms and tools.</p>
                </div>
                <div class="bg-white p-6 rounded-xl shadow-md text-center card-hover md:col-start-2 lg:col-start-auto">
                    <div class="text-4xl mb-3">üîó</div>
                    <h3 class="text-xl font-bold text-slate-800 mb-2">GraphX</h3>
                    <p class="text-slate-500">The API for graphs and graph-parallel computation for network analysis.</p>
                </div>
            </div>

            <div class="bg-white rounded-2xl shadow-xl p-10 mt-12">
                <h3 class="text-2xl font-bold text-slate-800 text-center mb-4">Why Spark Anchors Modern Data Platforms</h3>
                <p class="text-slate-600 text-center max-w-4xl mx-auto mb-8">Spark sits at the heart of contemporary big data ecosystems. It connects streaming sources, lakehouse storage, machine learning frameworks, and business intelligence surfaces into one continuous value chain.</p>
                <div class="spark-ecosystem-diagram">
                    <div class="spark-ecosystem-center flex flex-col items-center justify-center bg-sky-600 text-white rounded-full w-40 h-40 mx-auto">
                        <span class="text-sm uppercase tracking-wide">Unified Engine</span>
                        <span class="text-2xl font-bold">Apache Spark</span>
                    </div>
                    <div class="spark-ecosystem-node" style="top: -2rem; left: 50%; transform: translate(-50%, 0);">
                        Real-Time Streams<br><span class="text-sky-600 font-medium text-sm">Kafka ¬∑ Pulsar</span>
                    </div>
                    <div class="spark-ecosystem-node" style="top: 50%; left: -1rem; transform: translate(-100%, -50%);">
                        Data Lakes<br><span class="text-sky-600 font-medium text-sm">Delta ¬∑ Iceberg ¬∑ Hudi</span>
                    </div>
                    <div class="spark-ecosystem-node" style="top: 50%; right: -1rem; transform: translate(100%, -50%);">
                        ML/AI Tooling<br><span class="text-sky-600 font-medium text-sm">MLflow ¬∑ TensorFlow</span>
                    </div>
                    <div class="spark-ecosystem-node" style="bottom: -2rem; left: 25%; transform: translate(-50%, 0);">
                        BI &amp; SQL Access<br><span class="text-sky-600 font-medium text-sm">Tableau ¬∑ Power BI</span>
                    </div>
                    <div class="spark-ecosystem-node" style="bottom: -2rem; right: 25%; transform: translate(50%, 0);">
                        Orchestration<br><span class="text-sky-600 font-medium text-sm">Airflow ¬∑ dbt</span>
                    </div>
                </div>
                <p class="text-slate-600 text-center max-w-3xl mx-auto mt-8">Together, these tools enable streaming ingestion, medallion-style lakehouse modeling, advanced analytics, and low-latency dashboards‚Äîan end-to-end flow that Spark powers with a consistent API surface.</p>
            </div>
        </section>

        <section id="deployment" class="mb-24 scroll-mt-20">
            <h2 class="text-3xl font-bold text-center text-slate-900 mb-4">Infrastructure & Deployment</h2>
            <p class="text-lg text-slate-600 text-center max-w-3xl mx-auto mb-12">Spark's flexibility extends to its deployment. It can run on various infrastructures thanks to its cluster manager-agnostic design. This section compares the most common cluster managers, highlighting the industry's significant shift towards containerization with Kubernetes for cloud-native deployments.</p>
            <div class="bg-white p-6 rounded-xl shadow-lg">
                <div class="text-center mb-6">
                    <div id="cluster-buttons" class="inline-flex rounded-md shadow-sm" role="group">
                      <button type="button" class="btn-active px-4 py-2 text-sm font-medium text-white bg-sky-600 border border-sky-600 rounded-l-lg hover:bg-sky-700" data-manager="scalability">Scalability</button>
                      <button type="button" class="btn-inactive px-4 py-2 text-sm font-medium text-slate-900 bg-white border-t border-b border-slate-200 hover:bg-slate-100" data-manager="complexity">Operational Complexity</button>
                      <button type="button" class="btn-inactive px-4 py-2 text-sm font-medium text-slate-900 bg-white border border-slate-200 rounded-r-md hover:bg-slate-100" data-manager="usecase">Ideal Use Case</button>
                    </div>
                </div>
                <div class="chart-container">
                    <canvas id="clusterManagerChart"></canvas>
                </div>
            </div>
            <div class="bg-white p-6 rounded-xl shadow-lg mt-12">
                <h3 class="text-2xl font-bold text-slate-800 mb-4 text-center">Run Spark on Your Laptop in Minutes</h3>
                <ol class="list-decimal list-inside text-slate-600 space-y-2 max-w-3xl mx-auto text-left">
                    <li>Download the latest pre-built Spark package from <a href="https://spark.apache.org/downloads.html" class="text-sky-600 underline">spark.apache.org/downloads</a>, choosing the Hadoop version that matches your environment.</li>
                    <li>Extract the archive and set the <span class="font-mono">SPARK_HOME</span> environment variable to the extracted directory; add <span class="font-mono">$SPARK_HOME/bin</span> to your <span class="font-mono">PATH</span>.</li>
                    <li>Install Java if it is not already available, then launch an interactive shell with <span class="font-mono">$SPARK_HOME/bin/spark-shell</span> (Scala) or <span class="font-mono">pyspark</span> for Python to verify the installation.</li>
                </ol>
            </div>
        </section>

        <section id="use-cases" class="scroll-mt-20">
            <h2 class="text-3xl font-bold text-center text-slate-900 mb-4">Real-World Impact</h2>
            <p class="text-lg text-slate-600 text-center max-w-3xl mx-auto mb-12">Spark's power and versatility are best demonstrated by its adoption across diverse industries to solve critical business problems. From detecting fraud in real-time to delivering personalized entertainment, Spark enables companies to leverage data at scale. Explore some of the key applications below.</p>
            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-8">
                <div class="bg-white rounded-xl shadow-md p-8 card-hover">
                    <h3 class="text-xl font-bold text-slate-800 mb-3">üí≥ Financial Services</h3>
                    <p class="text-slate-600">Used for real-time fraud detection and risk modeling. Spark Streaming and MLlib analyze transaction data to identify anomalies instantly, saving millions and reducing risk.</p>
                </div>
                <div class="bg-white rounded-xl shadow-md p-8 card-hover">
                    <h3 class="text-xl font-bold text-slate-800 mb-3">üé¨ Media & Entertainment</h3>
                    <p class="text-slate-600">Powers personalized content recommendations for companies like Netflix. Spark analyzes viewing habits to enhance user experience and drive engagement.</p>
                </div>
                <div class="bg-white rounded-xl shadow-md p-8 card-hover">
                    <h3 class="text-xl font-bold text-slate-800 mb-3">üõí E-commerce</h3>
                    <p class="text-slate-600">Enables real-time customer analytics and personalized offers. Companies like Alibaba use Spark to analyze browsing and purchase history to improve conversion rates.</p>
                </div>
                <div class="bg-white rounded-xl shadow-md p-8 card-hover">
                    <h3 class="text-xl font-bold text-slate-800 mb-3">‚úàÔ∏è Travel & Hospitality</h3>
                    <p class="text-slate-600">Speeds up real-time reservations and personalized trip planning. Sites like TripAdvisor use Spark to compare prices and manage high volumes of bookings efficiently.</p>
                </div>
            </div>
        </section>
    </main>

    <footer class="bg-slate-800 text-slate-400 mt-24">
        <div class="container mx-auto px-6 py-8 text-center">
            <p>An Interactive Visualization of the Apache Spark Report.</p>
            <p class="text-sm mt-2">Designed to make complex data accessible and engaging.</p>
        </div>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const sections = document.querySelectorAll('main section');
            const navLinks = document.querySelectorAll('.nav-link');

            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.4
            };

            const observer = new IntersectionObserver((entries, observer) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        navLinks.forEach(link => {
                            link.classList.remove('active-link');
                            if (link.getAttribute('href').substring(1) === entry.target.id) {
                                link.classList.add('active-link');
                            }
                        });
                    }
                });
            }, observerOptions);

            sections.forEach(section => {
                observer.observe(section);
            });

            const architectureInfo = {
                driver: {
                    title: 'Driver Program',
                    text: 'The heart of a Spark application. It runs the main() function, creates the SparkContext, and coordinates all operations. It analyzes, distributes, and schedules tasks for the executors.'
                },
                manager: {
                    title: 'Cluster Manager',
                    text: 'An external service (like YARN, Mesos, or Kubernetes) responsible for acquiring and allocating cluster resources (CPU, memory) for the Spark application.'
                },
                executor: {
                    title: 'Executors',
                    text: 'Processes launched on worker nodes that execute the tasks assigned by the driver. They are also responsible for storing data partitions in memory or on disk.'
                }
            };

            window.showInfo = (component) => {
                const info = architectureInfo[component];
                document.getElementById('info-title').textContent = info.title;
                document.getElementById('info-text').textContent = info.text;
            };
            
            showInfo('driver');

            const clusterData = {
                labels: ['Standalone', 'YARN', 'Mesos', 'Kubernetes'],
                scalability: {
                    label: 'Scalability & Elasticity',
                    data: [5, 6, 8, 10],
                    backgroundColor: 'rgba(14, 165, 233, 0.6)',
                },
                complexity: {
                    label: 'Operational Complexity (Lower is Better)',
                    data: [2, 8, 9, 5],
                    backgroundColor: 'rgba(249, 115, 22, 0.6)',
                },
                usecase: {
                    label: 'Fit for Cloud-Native (Higher is Better)',
                    data: [2, 4, 5, 10],
                    backgroundColor: 'rgba(20, 184, 166, 0.6)',
                }
            };

            const clusterCtx = document.getElementById('clusterManagerChart').getContext('2d');
            const clusterManagerChart = new Chart(clusterCtx, {
                type: 'bar',
                data: {
                    labels: clusterData.labels,
                    datasets: [{
                        label: clusterData.scalability.label,
                        data: clusterData.scalability.data,
                        backgroundColor: clusterData.scalability.backgroundColor,
                        borderColor: clusterData.scalability.backgroundColor.replace('0.6', '1'),
                        borderWidth: 1
                    }]
                },
                options: {
                    maintainAspectRatio: false,
                    indexAxis: 'y',
                    scales: {
                        x: {
                            beginAtZero: true,
                            grid: {
                                color: '#e2e8f0'
                            },
                            ticks: {
                                font: { family: 'Inter' }
                            }
                        },
                        y: {
                           grid: {
                                display: false
                            },
                            ticks: {
                                font: { family: 'Inter', size: 14 }
                            }
                        }
                    },
                    plugins: {
                        legend: {
                            display: true,
                            position: 'bottom',
                             labels: {
                                font: {
                                    size: 14,
                                    family: 'Inter'
                                }
                            }
                        }
                    }
                }
            });

            const clusterButtons = document.getElementById('cluster-buttons');
            clusterButtons.addEventListener('click', (e) => {
                if (e.target.tagName === 'BUTTON') {
                    const managerType = e.target.dataset.manager;
                    const newDataset = clusterData[managerType];
                    
                    clusterManagerChart.data.datasets[0].data = newDataset.data;
                    clusterManagerChart.data.datasets[0].label = newDataset.label;
                    clusterManagerChart.data.datasets[0].backgroundColor = newDataset.backgroundColor;
                    clusterManagerChart.update();

                    clusterButtons.querySelectorAll('button').forEach(btn => {
                        btn.classList.remove('btn-active', 'text-white', 'bg-sky-600', 'border-sky-600');
                        btn.classList.add('btn-inactive', 'text-slate-900', 'bg-white', 'border-slate-200');
                    });
                    e.target.classList.add('btn-active', 'text-white', 'bg-sky-600', 'border-sky-600');
                    e.target.classList.remove('btn-inactive', 'text-slate-900', 'bg-white', 'border-slate-200');
                }
            });
        });
    </script>
</body>
</html>
